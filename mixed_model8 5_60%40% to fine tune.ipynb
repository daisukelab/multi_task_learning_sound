{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('common')\n",
    "import util, audio_preprocessing\n",
    "\n",
    "import shutil\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint, Callback, TensorBoard\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from cyclic_lr import CyclicLR\n",
    "\n",
    "from dataset import SingleDataset, MultiDataset\n",
    "from model import model_mlt_cnn_alexnet\n",
    "\n",
    "TRY = 'MIX8'\n",
    "BASE = 'MIX5'\n",
    "LOG_DIR = './%slog' % TRY\n",
    "SCD_PREFIX = 'scd_'\n",
    "USD_PREFIX = 'usd_'\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "scd = SingleDataset(SCD_PREFIX,\n",
    "                   util.load_txt_list(os.path.join('.', SCD_PREFIX+'classes.txt')),\n",
    "                   batch_size)\n",
    "usd = SingleDataset(USD_PREFIX,\n",
    "                   ['air_conditioner',  'car_horn', 'children_playing', 'dog_bark', 'drilling',\n",
    "                    'engine_idling', 'gun_shot','jackhammer', 'siren', 'street_music'],\n",
    "                   batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up log\n",
    "shutil.rmtree(LOG_DIR, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_mlt_cnn_alexnet: freeze other than output_1.\n",
      "Epoch 1/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7366 - output_1_loss: 1.7501 - output_2_loss: -0.0135 - output_1_acc: 0.7343 - output_2_acc: 0.1398\n",
      "Epoch 00001: val_output_1_acc improved from -inf to 0.92822, saving model to modelMIX8.h5\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.7372 - output_1_loss: 1.7503 - output_2_loss: -0.0131 - output_1_acc: 0.7344 - output_2_acc: 0.1398 - val_loss: 0.2587 - val_output_1_loss: 0.2786 - val_output_2_loss: -0.0199 - val_output_1_acc: 0.9282 - val_output_2_acc: 0.0977\n",
      "Epoch 2/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7272 - output_1_loss: 1.7486 - output_2_loss: -0.0214 - output_1_acc: 0.7348 - output_2_acc: 0.1419\n",
      "Epoch 00002: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7274 - output_1_loss: 1.7487 - output_2_loss: -0.0214 - output_1_acc: 0.7347 - output_2_acc: 0.1419 - val_loss: 0.2685 - val_output_1_loss: 0.2881 - val_output_2_loss: -0.0196 - val_output_1_acc: 0.9235 - val_output_2_acc: 0.0913\n",
      "Epoch 3/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.7465 - output_1_loss: 1.7550 - output_2_loss: -0.0085 - output_1_acc: 0.7349 - output_2_acc: 0.1401\n",
      "Epoch 00003: val_output_1_acc improved from 0.92822 to 0.93285, saving model to modelMIX8.h5\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7468 - output_1_loss: 1.7551 - output_2_loss: -0.0083 - output_1_acc: 0.7350 - output_2_acc: 0.1402 - val_loss: 0.2391 - val_output_1_loss: 0.2581 - val_output_2_loss: -0.0190 - val_output_1_acc: 0.9328 - val_output_2_acc: 0.0886\n",
      "Epoch 4/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7245 - output_1_loss: 1.7399 - output_2_loss: -0.0155 - output_1_acc: 0.7353 - output_2_acc: 0.1360\n",
      "Epoch 00004: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7248 - output_1_loss: 1.7400 - output_2_loss: -0.0153 - output_1_acc: 0.7353 - output_2_acc: 0.1359 - val_loss: 0.2705 - val_output_1_loss: 0.2872 - val_output_2_loss: -0.0167 - val_output_1_acc: 0.9246 - val_output_2_acc: 0.0916\n",
      "Epoch 5/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7305 - output_1_loss: 1.7427 - output_2_loss: -0.0122 - output_1_acc: 0.7359 - output_2_acc: 0.1373\n",
      "Epoch 00005: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.7309 - output_1_loss: 1.7429 - output_2_loss: -0.0120 - output_1_acc: 0.7359 - output_2_acc: 0.1373 - val_loss: 0.2614 - val_output_1_loss: 0.2803 - val_output_2_loss: -0.0189 - val_output_1_acc: 0.9314 - val_output_2_acc: 0.0899\n",
      "Epoch 6/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7335 - output_1_loss: 1.7463 - output_2_loss: -0.0128 - output_1_acc: 0.7360 - output_2_acc: 0.1415\n",
      "Epoch 00006: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7340 - output_1_loss: 1.7466 - output_2_loss: -0.0126 - output_1_acc: 0.7359 - output_2_acc: 0.1414 - val_loss: 0.2630 - val_output_1_loss: 0.2878 - val_output_2_loss: -0.0248 - val_output_1_acc: 0.9267 - val_output_2_acc: 0.0990\n",
      "Epoch 7/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.7540 - output_1_loss: 1.7583 - output_2_loss: -0.0043 - output_1_acc: 0.7335 - output_2_acc: 0.1397\n",
      "Epoch 00007: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.7548 - output_1_loss: 1.7589 - output_2_loss: -0.0041 - output_1_acc: 0.7333 - output_2_acc: 0.1398 - val_loss: 0.2474 - val_output_1_loss: 0.2693 - val_output_2_loss: -0.0219 - val_output_1_acc: 0.9313 - val_output_2_acc: 0.0998\n",
      "Epoch 8/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.7307 - output_1_loss: 1.7403 - output_2_loss: -0.0096 - output_1_acc: 0.7374 - output_2_acc: 0.1390\n",
      "Epoch 00008: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7310 - output_1_loss: 1.7404 - output_2_loss: -0.0094 - output_1_acc: 0.7374 - output_2_acc: 0.1390 - val_loss: 0.2553 - val_output_1_loss: 0.2764 - val_output_2_loss: -0.0211 - val_output_1_acc: 0.9294 - val_output_2_acc: 0.0892\n",
      "Epoch 9/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.7348 - output_1_loss: 1.7475 - output_2_loss: -0.0127 - output_1_acc: 0.7351 - output_2_acc: 0.1426\n",
      "Epoch 00009: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7340 - output_1_loss: 1.7472 - output_2_loss: -0.0131 - output_1_acc: 0.7350 - output_2_acc: 0.1425 - val_loss: 0.2601 - val_output_1_loss: 0.2792 - val_output_2_loss: -0.0190 - val_output_1_acc: 0.9276 - val_output_2_acc: 0.0873\n",
      "Epoch 10/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.7411 - output_1_loss: 1.7452 - output_2_loss: -0.0041 - output_1_acc: 0.7392 - output_2_acc: 0.1421\n",
      "Epoch 00010: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.7409 - output_1_loss: 1.7451 - output_2_loss: -0.0042 - output_1_acc: 0.7392 - output_2_acc: 0.1421 - val_loss: 0.2526 - val_output_1_loss: 0.2682 - val_output_2_loss: -0.0157 - val_output_1_acc: 0.9309 - val_output_2_acc: 0.0933\n",
      "Epoch 11/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7332 - output_1_loss: 1.7478 - output_2_loss: -0.0146 - output_1_acc: 0.7341 - output_2_acc: 0.1404\n",
      "Epoch 00011: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7334 - output_1_loss: 1.7479 - output_2_loss: -0.0145 - output_1_acc: 0.7341 - output_2_acc: 0.1404 - val_loss: 0.2554 - val_output_1_loss: 0.2801 - val_output_2_loss: -0.0248 - val_output_1_acc: 0.9267 - val_output_2_acc: 0.0855\n",
      "Epoch 12/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.6961 - output_1_loss: 1.7258 - output_2_loss: -0.0297 - output_1_acc: 0.7393 - output_2_acc: 0.1386\n",
      "Epoch 00012: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.6955 - output_1_loss: 1.7255 - output_2_loss: -0.0300 - output_1_acc: 0.7393 - output_2_acc: 0.1385 - val_loss: 0.2609 - val_output_1_loss: 0.2786 - val_output_2_loss: -0.0177 - val_output_1_acc: 0.9287 - val_output_2_acc: 0.0953\n",
      "Epoch 13/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7530 - output_1_loss: 1.7510 - output_2_loss: 0.0020 - output_1_acc: 0.7369 - output_2_acc: 0.1400\n",
      "Epoch 00013: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7533 - output_1_loss: 1.7512 - output_2_loss: 0.0022 - output_1_acc: 0.7369 - output_2_acc: 0.1401 - val_loss: 0.2700 - val_output_1_loss: 0.2919 - val_output_2_loss: -0.0219 - val_output_1_acc: 0.9236 - val_output_2_acc: 0.0859\n",
      "Epoch 14/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.7498 - output_1_loss: 1.7539 - output_2_loss: -0.0040 - output_1_acc: 0.7355 - output_2_acc: 0.1383\n",
      "Epoch 00014: val_output_1_acc improved from 0.93285 to 0.93310, saving model to modelMIX8.h5\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.7503 - output_1_loss: 1.7539 - output_2_loss: -0.0037 - output_1_acc: 0.7354 - output_2_acc: 0.1385 - val_loss: 0.2384 - val_output_1_loss: 0.2598 - val_output_2_loss: -0.0214 - val_output_1_acc: 0.9331 - val_output_2_acc: 0.0923\n",
      "Epoch 15/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7106 - output_1_loss: 1.7296 - output_2_loss: -0.0190 - output_1_acc: 0.7363 - output_2_acc: 0.1381\n",
      "Epoch 00015: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.7108 - output_1_loss: 1.7297 - output_2_loss: -0.0189 - output_1_acc: 0.7363 - output_2_acc: 0.1380 - val_loss: 0.2555 - val_output_1_loss: 0.2814 - val_output_2_loss: -0.0259 - val_output_1_acc: 0.9278 - val_output_2_acc: 0.0935\n",
      "Epoch 16/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.6925 - output_1_loss: 1.7224 - output_2_loss: -0.0299 - output_1_acc: 0.7394 - output_2_acc: 0.1399\n",
      "Epoch 00016: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.6924 - output_1_loss: 1.7224 - output_2_loss: -0.0299 - output_1_acc: 0.7393 - output_2_acc: 0.1399 - val_loss: 0.2621 - val_output_1_loss: 0.2731 - val_output_2_loss: -0.0109 - val_output_1_acc: 0.9313 - val_output_2_acc: 0.0954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7239 - output_1_loss: 1.7376 - output_2_loss: -0.0138 - output_1_acc: 0.7368 - output_2_acc: 0.1419\n",
      "Epoch 00017: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.7237 - output_1_loss: 1.7375 - output_2_loss: -0.0138 - output_1_acc: 0.7367 - output_2_acc: 0.1420 - val_loss: 0.2578 - val_output_1_loss: 0.2730 - val_output_2_loss: -0.0152 - val_output_1_acc: 0.9313 - val_output_2_acc: 0.0872\n",
      "Epoch 18/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7439 - output_1_loss: 1.7477 - output_2_loss: -0.0038 - output_1_acc: 0.7359 - output_2_acc: 0.1408\n",
      "Epoch 00018: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7437 - output_1_loss: 1.7476 - output_2_loss: -0.0040 - output_1_acc: 0.7359 - output_2_acc: 0.1407 - val_loss: 0.2593 - val_output_1_loss: 0.2766 - val_output_2_loss: -0.0173 - val_output_1_acc: 0.9275 - val_output_2_acc: 0.0905\n",
      "Epoch 19/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7493 - output_1_loss: 1.7532 - output_2_loss: -0.0038 - output_1_acc: 0.7348 - output_2_acc: 0.1382\n",
      "Epoch 00019: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.7488 - output_1_loss: 1.7529 - output_2_loss: -0.0041 - output_1_acc: 0.7349 - output_2_acc: 0.1381 - val_loss: 0.2587 - val_output_1_loss: 0.2767 - val_output_2_loss: -0.0181 - val_output_1_acc: 0.9293 - val_output_2_acc: 0.0913\n",
      "Epoch 20/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7421 - output_1_loss: 1.7497 - output_2_loss: -0.0077 - output_1_acc: 0.7371 - output_2_acc: 0.1414\n",
      "Epoch 00020: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.7418 - output_1_loss: 1.7497 - output_2_loss: -0.0078 - output_1_acc: 0.7371 - output_2_acc: 0.1414 - val_loss: 0.2595 - val_output_1_loss: 0.2802 - val_output_2_loss: -0.0207 - val_output_1_acc: 0.9260 - val_output_2_acc: 0.0949\n",
      "Evaluating scd_dataset\n",
      "6798/6798 [==============================] - 10s 1ms/step\n",
      " = 0.9320388349514563\n",
      "Evaluating usd_dataset\n",
      "990/990 [==============================] - 2s 2ms/step\n",
      " = 0.5292929292929293\n",
      "Accuracy with scd_dataset = 0.932039\n",
      "Accuracy with usd_dataset = 0.529293\n",
      "model_mlt_cnn_alexnet: freeze other than output_2.\n",
      "Epoch 1/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.4860 - output_1_loss: 0.0052 - output_2_loss: 1.4809 - output_1_acc: 0.0351 - output_2_acc: 0.6101\n",
      "Epoch 00001: val_output_2_acc improved from -inf to 0.56523, saving model to modelMIX8.h5\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4860 - output_1_loss: 0.0051 - output_2_loss: 1.4809 - output_1_acc: 0.0351 - output_2_acc: 0.6101 - val_loss: 1.3252 - val_output_1_loss: -0.0043 - val_output_2_loss: 1.3295 - val_output_1_acc: 0.0347 - val_output_2_acc: 0.5652\n",
      "Epoch 2/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.4379 - output_1_loss: -0.0104 - output_2_loss: 1.4482 - output_1_acc: 0.0351 - output_2_acc: 0.6239\n",
      "Epoch 00002: val_output_2_acc improved from 0.56523 to 0.56818, saving model to modelMIX8.h5\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4384 - output_1_loss: -0.0099 - output_2_loss: 1.4484 - output_1_acc: 0.0351 - output_2_acc: 0.6240 - val_loss: 1.3377 - val_output_1_loss: 0.0013 - val_output_2_loss: 1.3364 - val_output_1_acc: 0.0331 - val_output_2_acc: 0.5682\n",
      "Epoch 3/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.4554 - output_1_loss: 0.0090 - output_2_loss: 1.4465 - output_1_acc: 0.0362 - output_2_acc: 0.6227\n",
      "Epoch 00003: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4551 - output_1_loss: 0.0088 - output_2_loss: 1.4463 - output_1_acc: 0.0362 - output_2_acc: 0.6228 - val_loss: 1.3951 - val_output_1_loss: 0.0019 - val_output_2_loss: 1.3932 - val_output_1_acc: 0.0297 - val_output_2_acc: 0.5564\n",
      "Epoch 4/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.4346 - output_1_loss: 8.7765e-05 - output_2_loss: 1.4346 - output_1_acc: 0.0356 - output_2_acc: 0.6281\n",
      "Epoch 00004: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4339 - output_1_loss: -3.8725e-04 - output_2_loss: 1.4343 - output_1_acc: 0.0356 - output_2_acc: 0.6281 - val_loss: 1.3550 - val_output_1_loss: -0.0027 - val_output_2_loss: 1.3578 - val_output_1_acc: 0.0311 - val_output_2_acc: 0.5645\n",
      "Epoch 5/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.4186 - output_1_loss: -0.0092 - output_2_loss: 1.4278 - output_1_acc: 0.0344 - output_2_acc: 0.6297\n",
      "Epoch 00005: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4190 - output_1_loss: -0.0089 - output_2_loss: 1.4280 - output_1_acc: 0.0344 - output_2_acc: 0.6297 - val_loss: 1.3656 - val_output_1_loss: 0.0044 - val_output_2_loss: 1.3612 - val_output_1_acc: 0.0276 - val_output_2_acc: 0.5656\n",
      "Epoch 6/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.4295 - output_1_loss: 0.0032 - output_2_loss: 1.4262 - output_1_acc: 0.0363 - output_2_acc: 0.6318\n",
      "Epoch 00006: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4291 - output_1_loss: 0.0030 - output_2_loss: 1.4261 - output_1_acc: 0.0363 - output_2_acc: 0.6319 - val_loss: 1.3779 - val_output_1_loss: 7.3613e-04 - val_output_2_loss: 1.3771 - val_output_1_acc: 0.0336 - val_output_2_acc: 0.5553\n",
      "Epoch 7/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.4125 - output_1_loss: -0.0107 - output_2_loss: 1.4231 - output_1_acc: 0.0361 - output_2_acc: 0.6304\n",
      "Epoch 00007: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4126 - output_1_loss: -0.0106 - output_2_loss: 1.4231 - output_1_acc: 0.0361 - output_2_acc: 0.6304 - val_loss: 1.3766 - val_output_1_loss: -0.0059 - val_output_2_loss: 1.3825 - val_output_1_acc: 0.0428 - val_output_2_acc: 0.5646\n",
      "Epoch 8/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.4204 - output_1_loss: -0.0035 - output_2_loss: 1.4239 - output_1_acc: 0.0353 - output_2_acc: 0.6307\n",
      "Epoch 00008: val_output_2_acc improved from 0.56818 to 0.57036, saving model to modelMIX8.h5\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4209 - output_1_loss: -0.0028 - output_2_loss: 1.4238 - output_1_acc: 0.0354 - output_2_acc: 0.6309 - val_loss: 1.3846 - val_output_1_loss: 0.0050 - val_output_2_loss: 1.3796 - val_output_1_acc: 0.0357 - val_output_2_acc: 0.5704\n",
      "Epoch 9/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.4032 - output_1_loss: -0.0101 - output_2_loss: 1.4133 - output_1_acc: 0.0349 - output_2_acc: 0.6345\n",
      "Epoch 00009: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4039 - output_1_loss: -0.0096 - output_2_loss: 1.4135 - output_1_acc: 0.0350 - output_2_acc: 0.6345 - val_loss: 1.4053 - val_output_1_loss: 0.0110 - val_output_2_loss: 1.3943 - val_output_1_acc: 0.0306 - val_output_2_acc: 0.5619\n",
      "Epoch 10/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.4146 - output_1_loss: -0.0026 - output_2_loss: 1.4172 - output_1_acc: 0.0378 - output_2_acc: 0.6370\n",
      "Epoch 00010: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4144 - output_1_loss: -0.0028 - output_2_loss: 1.4171 - output_1_acc: 0.0378 - output_2_acc: 0.6370 - val_loss: 1.3834 - val_output_1_loss: 3.6275e-04 - val_output_2_loss: 1.3831 - val_output_1_acc: 0.0273 - val_output_2_acc: 0.5663\n",
      "Epoch 11/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.4106 - output_1_loss: -0.0058 - output_2_loss: 1.4164 - output_1_acc: 0.0362 - output_2_acc: 0.6355\n",
      "Epoch 00011: val_output_2_acc improved from 0.57036 to 0.57242, saving model to modelMIX8.h5\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4103 - output_1_loss: -0.0060 - output_2_loss: 1.4163 - output_1_acc: 0.0362 - output_2_acc: 0.6355 - val_loss: 1.3645 - val_output_1_loss: -0.0059 - val_output_2_loss: 1.3703 - val_output_1_acc: 0.0300 - val_output_2_acc: 0.5724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.4116 - output_1_loss: -0.0020 - output_2_loss: 1.4136 - output_1_acc: 0.0356 - output_2_acc: 0.6370\n",
      "Epoch 00012: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4121 - output_1_loss: -0.0017 - output_2_loss: 1.4138 - output_1_acc: 0.0356 - output_2_acc: 0.6370 - val_loss: 1.4328 - val_output_1_loss: 0.0042 - val_output_2_loss: 1.4286 - val_output_1_acc: 0.0315 - val_output_2_acc: 0.5597\n",
      "Epoch 13/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.3720 - output_1_loss: -0.0306 - output_2_loss: 1.4026 - output_1_acc: 0.0348 - output_2_acc: 0.6329\n",
      "Epoch 00013: val_output_2_acc improved from 0.57242 to 0.57756, saving model to modelMIX8.h5\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.3718 - output_1_loss: -0.0308 - output_2_loss: 1.4025 - output_1_acc: 0.0349 - output_2_acc: 0.6328 - val_loss: 1.3338 - val_output_1_loss: 0.0016 - val_output_2_loss: 1.3322 - val_output_1_acc: 0.0402 - val_output_2_acc: 0.5776\n",
      "Epoch 14/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.4250 - output_1_loss: 0.0042 - output_2_loss: 1.4208 - output_1_acc: 0.0367 - output_2_acc: 0.6365\n",
      "Epoch 00014: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4245 - output_1_loss: 0.0040 - output_2_loss: 1.4205 - output_1_acc: 0.0367 - output_2_acc: 0.6365 - val_loss: 1.3850 - val_output_1_loss: -0.0029 - val_output_2_loss: 1.3879 - val_output_1_acc: 0.0324 - val_output_2_acc: 0.5722\n",
      "Epoch 15/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.3779 - output_1_loss: -0.0257 - output_2_loss: 1.4036 - output_1_acc: 0.0361 - output_2_acc: 0.6375\n",
      "Epoch 00015: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.3778 - output_1_loss: -0.0257 - output_2_loss: 1.4035 - output_1_acc: 0.0361 - output_2_acc: 0.6375 - val_loss: 1.4003 - val_output_1_loss: 0.0032 - val_output_2_loss: 1.3971 - val_output_1_acc: 0.0329 - val_output_2_acc: 0.5701\n",
      "Epoch 16/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.4085 - output_1_loss: -2.1149e-04 - output_2_loss: 1.4087 - output_1_acc: 0.0369 - output_2_acc: 0.6379\n",
      "Epoch 00016: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4091 - output_1_loss: 2.3803e-04 - output_2_loss: 1.4089 - output_1_acc: 0.0368 - output_2_acc: 0.6380 - val_loss: 1.4086 - val_output_1_loss: 1.3071e-04 - val_output_2_loss: 1.4085 - val_output_1_acc: 0.0327 - val_output_2_acc: 0.5713\n",
      "Epoch 17/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.4254 - output_1_loss: 0.0122 - output_2_loss: 1.4132 - output_1_acc: 0.0351 - output_2_acc: 0.6401\n",
      "Epoch 00017: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4251 - output_1_loss: 0.0120 - output_2_loss: 1.4130 - output_1_acc: 0.0351 - output_2_acc: 0.6402 - val_loss: 1.4341 - val_output_1_loss: 0.0044 - val_output_2_loss: 1.4297 - val_output_1_acc: 0.0304 - val_output_2_acc: 0.5628\n",
      "Epoch 18/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.3879 - output_1_loss: -0.0150 - output_2_loss: 1.4029 - output_1_acc: 0.0353 - output_2_acc: 0.6398\n",
      "Epoch 00018: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.3890 - output_1_loss: -0.0142 - output_2_loss: 1.4032 - output_1_acc: 0.0354 - output_2_acc: 0.6399 - val_loss: 1.4793 - val_output_1_loss: 0.0044 - val_output_2_loss: 1.4749 - val_output_1_acc: 0.0297 - val_output_2_acc: 0.5555\n",
      "Epoch 19/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.4277 - output_1_loss: 0.0156 - output_2_loss: 1.4120 - output_1_acc: 0.0366 - output_2_acc: 0.6416\n",
      "Epoch 00019: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4269 - output_1_loss: 0.0150 - output_2_loss: 1.4119 - output_1_acc: 0.0366 - output_2_acc: 0.6416 - val_loss: 1.3968 - val_output_1_loss: 0.0075 - val_output_2_loss: 1.3893 - val_output_1_acc: 0.0280 - val_output_2_acc: 0.5711\n",
      "Epoch 20/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.4070 - output_1_loss: -0.0015 - output_2_loss: 1.4085 - output_1_acc: 0.0361 - output_2_acc: 0.6380\n",
      "Epoch 00020: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 73s 46ms/step - loss: 1.4067 - output_1_loss: -0.0018 - output_2_loss: 1.4084 - output_1_acc: 0.0361 - output_2_acc: 0.6380 - val_loss: 1.4424 - val_output_1_loss: 0.0028 - val_output_2_loss: 1.4395 - val_output_1_acc: 0.0464 - val_output_2_acc: 0.5596\n",
      "Evaluating scd_dataset\n",
      "6798/6798 [==============================] - 11s 2ms/step\n",
      " = 0.9315975286849073\n",
      "Evaluating usd_dataset\n",
      "990/990 [==============================] - 1s 1ms/step\n",
      " = 0.5707070707070707\n",
      "Accuracy with scd_dataset = 0.931598\n",
      "Accuracy with usd_dataset = 0.570707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9315975286849073, 0.5707070707070707]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine tune for scd\n",
    "multi = MultiDataset([scd, usd], [1.0, 0.0])\n",
    "\n",
    "model = model_mlt_cnn_alexnet(multi.input_shape(), multi.ys_classes(), freeze_mode=1)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "model.load_weights('model%s.h5' % BASE) ### Starting point\n",
    "\n",
    "callbacks = [\n",
    "    CyclicLR(base_lr=0.00007, max_lr=0.0007, step_size=multi.train_steps_per_epoch, mode='triangular'),\n",
    "    ModelCheckpoint('model%s.h5' % TRY,\n",
    "                monitor='val_output_1_acc',\n",
    "                verbose=1,\n",
    "                save_best_only=True,\n",
    "                save_weights_only=True),\n",
    "     keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=0, write_graph=True, write_images=True)\n",
    "]\n",
    "model.fit_generator(multi.train_generator,\n",
    "                    steps_per_epoch=multi.train_steps_per_epoch,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=multi.valid_generator, \n",
    "                    validation_steps=multi.valid_steps_per_epoch,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "multi.evaluate_by_datasets(model)\n",
    "\n",
    "# Fine tune for usd\n",
    "multi = MultiDataset([scd, usd], [0.0, 1.0])\n",
    "\n",
    "model = model_mlt_cnn_alexnet(multi.input_shape(), multi.ys_classes(), freeze_mode=2)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "model.load_weights('model%s.h5' % TRY)\n",
    "\n",
    "callbacks = [\n",
    "    CyclicLR(base_lr=0.00007, max_lr=0.0007, step_size=multi.train_steps_per_epoch, mode='triangular'),\n",
    "    ModelCheckpoint('model%s.h5' % TRY,\n",
    "                monitor='val_output_2_acc',\n",
    "                verbose=1,\n",
    "                save_best_only=True,\n",
    "                save_weights_only=True),\n",
    "     keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=0, write_graph=True, write_images=True)\n",
    "]\n",
    "model.fit_generator(multi.train_generator,\n",
    "                    steps_per_epoch=multi.train_steps_per_epoch,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=multi.valid_generator, \n",
    "                    validation_steps=multi.valid_steps_per_epoch,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "multi.evaluate_by_datasets(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating scd_dataset\n",
      "6798/6798 [==============================] - 11s 2ms/step\n",
      " = 0.9315975286849073\n",
      "Evaluating usd_dataset\n",
      "990/990 [==============================] - 1s 1ms/step\n",
      " = 0.591919191919192\n",
      "Accuracy with scd_dataset = 0.931598\n",
      "Accuracy with usd_dataset = 0.591919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9315975286849073, 0.591919191919192]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('model%s.h5' % TRY)\n",
    "multi.evaluate_by_datasets(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate by mixed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'output_1_loss', 'output_2_loss', 'output_1_acc', 'output_2_acc'] [0.8764950239970615, 0.2698882808780865, 0.6066067431976614, 0.8957370313302516, 0.48266563944530044]\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('model%s.h5' % TRY)\n",
    "multi = MultiDataset([scd, usd], [0.6, 0.4], mix_randomness=0.0)\n",
    "results = model.evaluate_generator(multi.valid_generator, steps=multi.valid_steps_per_epoch)\n",
    "print(model.metrics_names, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
