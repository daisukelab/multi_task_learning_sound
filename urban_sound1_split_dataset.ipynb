{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset\n",
    "\n",
    "- [Link to Urban Sound 8k dataset description](https://serv.cusp.nyu.edu/projects/urbansounddataset/urbansound8k.html)\n",
    "\n",
    "The dataset is provided in 10 folders.\n",
    "\n",
    "Here we define training, validation and test set for further evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# load original listing\n",
    "DATADIR = '../../dataset/UrbanSound8K'\n",
    "metadata = pd.read_csv(os.path.join(DATADIR, 'metadata', 'UrbanSound8K.csv'))\n",
    "DATASET_PREFIX = 'usd_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niz/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[100, 36, 100, 100, 100, 96, 35, 120, 86, 100],\n",
       " [100, 42, 100, 100, 100, 100, 35, 120, 91, 100],\n",
       " [100, 43, 100, 100, 100, 107, 36, 120, 119, 100],\n",
       " [100, 59, 100, 100, 100, 107, 38, 120, 166, 100],\n",
       " [100, 98, 100, 100, 100, 107, 40, 120, 71, 100],\n",
       " [100, 28, 100, 100, 100, 107, 46, 68, 74, 100],\n",
       " [100, 28, 100, 100, 100, 106, 51, 76, 77, 100],\n",
       " [100, 30, 100, 100, 100, 88, 30, 78, 80, 100],\n",
       " [100, 32, 100, 100, 100, 89, 31, 82, 82, 100],\n",
       " [100, 33, 100, 100, 100, 93, 32, 96, 83, 100]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for number of samples per class, class balance for each fold\n",
    "classIDs = sorted(metadata['classID'].unique())\n",
    "foldIDs = sorted(metadata['fold'].unique())\n",
    "samples_per_class = [[len(metadata[metadata.fold == f][metadata.classID == i]) for i in classIDs] for f in foldIDs]\n",
    "samples_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It's imbalanced among classes... 3 classes need more data.\n",
    "\n",
    "But basically all folders have almost the similar balance.\n",
    "\n",
    "## Confirm duplicated source\n",
    "Handling datasets like audio, we need to be careful not to have the same data source in both training and validation sets.\n",
    "\n",
    "Here I confirm no duplication of data source in each folder; all folder shouldn't contain the same Freesound ID (fsID).\n",
    "Then we can be safe as long as splitting dataset by no duplicated combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fsIDs = [metadata[metadata.fold == f].fsID.unique() for f in foldIDs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated in folder 0 and 3, for 2 sources\n",
      "Duplicated in folder 0 and 7, for 1 sources\n",
      "Duplicated in folder 0 and 8, for 1 sources\n",
      "Duplicated in folder 1 and 6, for 1 sources\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "for i, j in itertools.combinations(range(len(fsIDs)), 2):\n",
    "    _or = np.append(fsIDs[i], fsIDs[j])\n",
    "    _and = np.unique(_or)\n",
    "    if len(_or) != len(_and):\n",
    "        print('Duplicated in folder %d and %d, for %d sources' % (i, j, len(_or) - len(_and)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we should not use the two folder combinations listed above.\n",
    "\n",
    "## Splitting dataset to train/valid/test.\n",
    "\n",
    "To simply just avoid combination above, use following folder combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainfolders = [0, 1, 2, 3,   6, 7, 8, 9]\n",
    "validfolders = [4]\n",
    "testfolders = [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "slice_file_name    5969\n",
       "fsID               5969\n",
       "start              5969\n",
       "end                5969\n",
       "salience           5969\n",
       "fold               5969\n",
       "classID            5969\n",
       "class              5969\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata = pd.DataFrame()\n",
    "for f in trainfolders:\n",
    "    traindata = traindata.append(metadata[metadata.fold == f])\n",
    "traindata.to_csv(os.path.join('.', DATASET_PREFIX+'train_list.csv'))\n",
    "traindata.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "slice_file_name    990\n",
       "fsID               990\n",
       "start              990\n",
       "end                990\n",
       "salience           990\n",
       "fold               990\n",
       "classID            990\n",
       "class              990\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdata = pd.DataFrame()\n",
    "for f in validfolders:\n",
    "    valdata = valdata.append(metadata[metadata.fold == f])\n",
    "valdata.to_csv(os.path.join('.', DATASET_PREFIX+'validation_list.csv'))\n",
    "valdata.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "slice_file_name    936\n",
       "fsID               936\n",
       "start              936\n",
       "end                936\n",
       "salience           936\n",
       "fold               936\n",
       "classID            936\n",
       "class              936\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata = pd.DataFrame()\n",
    "for f in testfolders:\n",
    "    testdata = testdata.append(metadata[metadata.fold == f])\n",
    "testdata.to_csv(os.path.join('.', DATASET_PREFIX+'test_list.csv'))\n",
    "testdata.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
