{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('common')\n",
    "import util, audio_preprocessing\n",
    "\n",
    "import shutil\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint, Callback, TensorBoard\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from cyclic_lr import CyclicLR\n",
    "\n",
    "from dataset import SingleDataset, MultiDataset\n",
    "from model import model_mlt_cnn_alexnet\n",
    "\n",
    "TRY = 'MIX9'\n",
    "BASE = 'MIX6'\n",
    "LOG_DIR = './%slog' % TRY\n",
    "SCD_PREFIX = 'scd_'\n",
    "USD_PREFIX = 'usd_'\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "scd = SingleDataset(SCD_PREFIX,\n",
    "                   util.load_txt_list(os.path.join('.', SCD_PREFIX+'classes.txt')),\n",
    "                   batch_size)\n",
    "usd = SingleDataset(USD_PREFIX,\n",
    "                   ['air_conditioner',  'car_horn', 'children_playing', 'dog_bark', 'drilling',\n",
    "                    'engine_idling', 'gun_shot','jackhammer', 'siren', 'street_music'],\n",
    "                   batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up log\n",
    "shutil.rmtree(LOG_DIR, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_mlt_cnn_alexnet: freeze other than output_1.\n",
      "Epoch 1/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.7466 - output_1_loss: 1.7599 - output_2_loss: -0.0133 - output_1_acc: 0.7334 - output_2_acc: 0.1444\n",
      "Epoch 00001: val_output_1_acc improved from -inf to 0.93182, saving model to modelMIX9.h5\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.7468 - output_1_loss: 1.7600 - output_2_loss: -0.0132 - output_1_acc: 0.7334 - output_2_acc: 0.1444 - val_loss: 0.2562 - val_output_1_loss: 0.2695 - val_output_2_loss: -0.0133 - val_output_1_acc: 0.9318 - val_output_2_acc: 0.0922\n",
      "Epoch 2/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.7594 - output_1_loss: 1.7646 - output_2_loss: -0.0052 - output_1_acc: 0.7337 - output_2_acc: 0.1414\n",
      "Epoch 00002: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7588 - output_1_loss: 1.7644 - output_2_loss: -0.0056 - output_1_acc: 0.7337 - output_2_acc: 0.1414 - val_loss: 0.2476 - val_output_1_loss: 0.2606 - val_output_2_loss: -0.0130 - val_output_1_acc: 0.9303 - val_output_2_acc: 0.0939\n",
      "Epoch 3/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7464 - output_1_loss: 1.7626 - output_2_loss: -0.0162 - output_1_acc: 0.7287 - output_2_acc: 0.1402\n",
      "Epoch 00003: val_output_1_acc improved from 0.93182 to 0.93593, saving model to modelMIX9.h5\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7464 - output_1_loss: 1.7626 - output_2_loss: -0.0163 - output_1_acc: 0.7287 - output_2_acc: 0.1402 - val_loss: 0.2275 - val_output_1_loss: 0.2435 - val_output_2_loss: -0.0160 - val_output_1_acc: 0.9359 - val_output_2_acc: 0.0892\n",
      "Epoch 4/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7395 - output_1_loss: 1.7519 - output_2_loss: -0.0125 - output_1_acc: 0.7308 - output_2_acc: 0.1409\n",
      "Epoch 00004: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7394 - output_1_loss: 1.7519 - output_2_loss: -0.0125 - output_1_acc: 0.7308 - output_2_acc: 0.1408 - val_loss: 0.2564 - val_output_1_loss: 0.2668 - val_output_2_loss: -0.0104 - val_output_1_acc: 0.9316 - val_output_2_acc: 0.0919\n",
      "Epoch 5/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7372 - output_1_loss: 1.7519 - output_2_loss: -0.0147 - output_1_acc: 0.7306 - output_2_acc: 0.1436\n",
      "Epoch 00005: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7371 - output_1_loss: 1.7518 - output_2_loss: -0.0147 - output_1_acc: 0.7306 - output_2_acc: 0.1436 - val_loss: 0.2443 - val_output_1_loss: 0.2533 - val_output_2_loss: -0.0090 - val_output_1_acc: 0.9359 - val_output_2_acc: 0.0932\n",
      "Epoch 6/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.7529 - output_1_loss: 1.7607 - output_2_loss: -0.0077 - output_1_acc: 0.7316 - output_2_acc: 0.1441\n",
      "Epoch 00006: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7529 - output_1_loss: 1.7606 - output_2_loss: -0.0077 - output_1_acc: 0.7317 - output_2_acc: 0.1441 - val_loss: 0.2581 - val_output_1_loss: 0.2732 - val_output_2_loss: -0.0151 - val_output_1_acc: 0.9299 - val_output_2_acc: 0.0883\n",
      "Epoch 7/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7447 - output_1_loss: 1.7530 - output_2_loss: -0.0084 - output_1_acc: 0.7359 - output_2_acc: 0.1412\n",
      "Epoch 00007: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7445 - output_1_loss: 1.7529 - output_2_loss: -0.0085 - output_1_acc: 0.7359 - output_2_acc: 0.1412 - val_loss: 0.2425 - val_output_1_loss: 0.2544 - val_output_2_loss: -0.0119 - val_output_1_acc: 0.9358 - val_output_2_acc: 0.0968\n",
      "Epoch 8/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.7430 - output_1_loss: 1.7563 - output_2_loss: -0.0133 - output_1_acc: 0.7307 - output_2_acc: 0.1414\n",
      "Epoch 00008: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7420 - output_1_loss: 1.7558 - output_2_loss: -0.0138 - output_1_acc: 0.7307 - output_2_acc: 0.1414 - val_loss: 0.2517 - val_output_1_loss: 0.2634 - val_output_2_loss: -0.0117 - val_output_1_acc: 0.9336 - val_output_2_acc: 0.0846\n",
      "Epoch 9/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.7266 - output_1_loss: 1.7452 - output_2_loss: -0.0186 - output_1_acc: 0.7336 - output_2_acc: 0.1411\n",
      "Epoch 00009: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7271 - output_1_loss: 1.7455 - output_2_loss: -0.0184 - output_1_acc: 0.7336 - output_2_acc: 0.1411 - val_loss: 0.2499 - val_output_1_loss: 0.2689 - val_output_2_loss: -0.0190 - val_output_1_acc: 0.9287 - val_output_2_acc: 0.0868\n",
      "Epoch 10/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7464 - output_1_loss: 1.7550 - output_2_loss: -0.0086 - output_1_acc: 0.7307 - output_2_acc: 0.1424\n",
      "Epoch 00010: val_output_1_acc improved from 0.93593 to 0.93657, saving model to modelMIX9.h5\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7459 - output_1_loss: 1.7548 - output_2_loss: -0.0089 - output_1_acc: 0.7307 - output_2_acc: 0.1423 - val_loss: 0.2385 - val_output_1_loss: 0.2493 - val_output_2_loss: -0.0108 - val_output_1_acc: 0.9366 - val_output_2_acc: 0.0982\n",
      "Epoch 11/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7380 - output_1_loss: 1.7513 - output_2_loss: -0.0133 - output_1_acc: 0.7338 - output_2_acc: 0.1397\n",
      "Epoch 00011: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7385 - output_1_loss: 1.7516 - output_2_loss: -0.0131 - output_1_acc: 0.7337 - output_2_acc: 0.1397 - val_loss: 0.2520 - val_output_1_loss: 0.2666 - val_output_2_loss: -0.0145 - val_output_1_acc: 0.9323 - val_output_2_acc: 0.0990\n",
      "Epoch 12/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7161 - output_1_loss: 1.7413 - output_2_loss: -0.0252 - output_1_acc: 0.7343 - output_2_acc: 0.1418\n",
      "Epoch 00012: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7161 - output_1_loss: 1.7413 - output_2_loss: -0.0252 - output_1_acc: 0.7343 - output_2_acc: 0.1417 - val_loss: 0.2535 - val_output_1_loss: 0.2630 - val_output_2_loss: -0.0094 - val_output_1_acc: 0.9348 - val_output_2_acc: 0.0933\n",
      "Epoch 13/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7479 - output_1_loss: 1.7566 - output_2_loss: -0.0088 - output_1_acc: 0.7341 - output_2_acc: 0.1428\n",
      "Epoch 00013: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7484 - output_1_loss: 1.7569 - output_2_loss: -0.0085 - output_1_acc: 0.7341 - output_2_acc: 0.1428 - val_loss: 0.2552 - val_output_1_loss: 0.2701 - val_output_2_loss: -0.0149 - val_output_1_acc: 0.9299 - val_output_2_acc: 0.0845\n",
      "Epoch 14/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7086 - output_1_loss: 1.7381 - output_2_loss: -0.0295 - output_1_acc: 0.7332 - output_2_acc: 0.1397\n",
      "Epoch 00014: val_output_1_acc improved from 0.93657 to 0.93760, saving model to modelMIX9.h5\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.7091 - output_1_loss: 1.7382 - output_2_loss: -0.0292 - output_1_acc: 0.7333 - output_2_acc: 0.1397 - val_loss: 0.2302 - val_output_1_loss: 0.2463 - val_output_2_loss: -0.0161 - val_output_1_acc: 0.9376 - val_output_2_acc: 0.0917\n",
      "Epoch 15/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7208 - output_1_loss: 1.7423 - output_2_loss: -0.0215 - output_1_acc: 0.7331 - output_2_acc: 0.1382\n",
      "Epoch 00015: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7211 - output_1_loss: 1.7425 - output_2_loss: -0.0214 - output_1_acc: 0.7331 - output_2_acc: 0.1382 - val_loss: 0.2492 - val_output_1_loss: 0.2684 - val_output_2_loss: -0.0192 - val_output_1_acc: 0.9317 - val_output_2_acc: 0.0922\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7460 - output_1_loss: 1.7510 - output_2_loss: -0.0050 - output_1_acc: 0.7316 - output_2_acc: 0.1448\n",
      "Epoch 00016: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7458 - output_1_loss: 1.7509 - output_2_loss: -0.0051 - output_1_acc: 0.7316 - output_2_acc: 0.1448 - val_loss: 0.2462 - val_output_1_loss: 0.2620 - val_output_2_loss: -0.0158 - val_output_1_acc: 0.9316 - val_output_2_acc: 0.0909\n",
      "Epoch 17/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7336 - output_1_loss: 1.7477 - output_2_loss: -0.0141 - output_1_acc: 0.7343 - output_2_acc: 0.1409\n",
      "Epoch 00017: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7334 - output_1_loss: 1.7477 - output_2_loss: -0.0143 - output_1_acc: 0.7343 - output_2_acc: 0.1408 - val_loss: 0.2480 - val_output_1_loss: 0.2630 - val_output_2_loss: -0.0150 - val_output_1_acc: 0.9325 - val_output_2_acc: 0.0927\n",
      "Epoch 18/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.7413 - output_1_loss: 1.7506 - output_2_loss: -0.0093 - output_1_acc: 0.7332 - output_2_acc: 0.1454\n",
      "Epoch 00018: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7409 - output_1_loss: 1.7503 - output_2_loss: -0.0094 - output_1_acc: 0.7333 - output_2_acc: 0.1453 - val_loss: 0.2505 - val_output_1_loss: 0.2602 - val_output_2_loss: -0.0097 - val_output_1_acc: 0.9337 - val_output_2_acc: 0.0960\n",
      "Epoch 19/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7468 - output_1_loss: 1.7514 - output_2_loss: -0.0046 - output_1_acc: 0.7316 - output_2_acc: 0.1403\n",
      "Epoch 00019: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7471 - output_1_loss: 1.7516 - output_2_loss: -0.0045 - output_1_acc: 0.7316 - output_2_acc: 0.1403 - val_loss: 0.2523 - val_output_1_loss: 0.2680 - val_output_2_loss: -0.0158 - val_output_1_acc: 0.9312 - val_output_2_acc: 0.0921\n",
      "Epoch 20/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.7354 - output_1_loss: 1.7451 - output_2_loss: -0.0097 - output_1_acc: 0.7352 - output_2_acc: 0.1411\n",
      "Epoch 00020: val_output_1_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.7351 - output_1_loss: 1.7451 - output_2_loss: -0.0100 - output_1_acc: 0.7352 - output_2_acc: 0.1412 - val_loss: 0.2508 - val_output_1_loss: 0.2635 - val_output_2_loss: -0.0126 - val_output_1_acc: 0.9316 - val_output_2_acc: 0.0945\n",
      "Evaluating scd_dataset\n",
      "6798/6798 [==============================] - 10s 2ms/step\n",
      " = 0.9349808767284495\n",
      "Evaluating usd_dataset\n",
      "990/990 [==============================] - 1s 1ms/step\n",
      " = 0.5272727272727272\n",
      "Accuracy with scd_dataset = 0.934981\n",
      "Accuracy with usd_dataset = 0.527273\n",
      "model_mlt_cnn_alexnet: freeze other than output_2.\n",
      "Epoch 1/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.4732 - output_1_loss: 0.0026 - output_2_loss: 1.4706 - output_1_acc: 0.0417 - output_2_acc: 0.6181\n",
      "Epoch 00001: val_output_2_acc improved from -inf to 0.52363, saving model to modelMIX9.h5\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4737 - output_1_loss: 0.0030 - output_2_loss: 1.4707 - output_1_acc: 0.0416 - output_2_acc: 0.6181 - val_loss: 1.4045 - val_output_1_loss: -0.0016 - val_output_2_loss: 1.4061 - val_output_1_acc: 0.0266 - val_output_2_acc: 0.5236\n",
      "Epoch 2/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.4173 - output_1_loss: -0.0154 - output_2_loss: 1.4327 - output_1_acc: 0.0400 - output_2_acc: 0.6294\n",
      "Epoch 00002: val_output_2_acc improved from 0.52363 to 0.53223, saving model to modelMIX9.h5\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4176 - output_1_loss: -0.0152 - output_2_loss: 1.4328 - output_1_acc: 0.0400 - output_2_acc: 0.6294 - val_loss: 1.4106 - val_output_1_loss: 0.0127 - val_output_2_loss: 1.3978 - val_output_1_acc: 0.0293 - val_output_2_acc: 0.5322\n",
      "Epoch 3/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.4177 - output_1_loss: -0.0112 - output_2_loss: 1.4289 - output_1_acc: 0.0407 - output_2_acc: 0.6311\n",
      "Epoch 00003: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4174 - output_1_loss: -0.0114 - output_2_loss: 1.4288 - output_1_acc: 0.0407 - output_2_acc: 0.6311 - val_loss: 1.4489 - val_output_1_loss: 0.0035 - val_output_2_loss: 1.4454 - val_output_1_acc: 0.0254 - val_output_2_acc: 0.5217\n",
      "Epoch 4/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.4150 - output_1_loss: -0.0085 - output_2_loss: 1.4235 - output_1_acc: 0.0421 - output_2_acc: 0.6332\n",
      "Epoch 00004: val_output_2_acc improved from 0.53223 to 0.53942, saving model to modelMIX9.h5\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4157 - output_1_loss: -0.0081 - output_2_loss: 1.4238 - output_1_acc: 0.0421 - output_2_acc: 0.6332 - val_loss: 1.3825 - val_output_1_loss: 0.0057 - val_output_2_loss: 1.3767 - val_output_1_acc: 0.0252 - val_output_2_acc: 0.5394\n",
      "Epoch 5/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.3999 - output_1_loss: -0.0166 - output_2_loss: 1.4164 - output_1_acc: 0.0403 - output_2_acc: 0.6352\n",
      "Epoch 00005: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.3997 - output_1_loss: -0.0168 - output_2_loss: 1.4165 - output_1_acc: 0.0403 - output_2_acc: 0.6350 - val_loss: 1.4127 - val_output_1_loss: 0.0082 - val_output_2_loss: 1.4045 - val_output_1_acc: 0.0326 - val_output_2_acc: 0.5199\n",
      "Epoch 6/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.4484 - output_1_loss: 0.0216 - output_2_loss: 1.4268 - output_1_acc: 0.0410 - output_2_acc: 0.6367\n",
      "Epoch 00006: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4478 - output_1_loss: 0.0212 - output_2_loss: 1.4266 - output_1_acc: 0.0410 - output_2_acc: 0.6367 - val_loss: 1.3919 - val_output_1_loss: 0.0101 - val_output_2_loss: 1.3818 - val_output_1_acc: 0.0413 - val_output_2_acc: 0.5380\n",
      "Epoch 7/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.4149 - output_1_loss: -0.0011 - output_2_loss: 1.4160 - output_1_acc: 0.0424 - output_2_acc: 0.6346\n",
      "Epoch 00007: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4155 - output_1_loss: -7.6175e-04 - output_2_loss: 1.4163 - output_1_acc: 0.0424 - output_2_acc: 0.6346 - val_loss: 1.3836 - val_output_1_loss: 8.5257e-04 - val_output_2_loss: 1.3827 - val_output_1_acc: 0.0340 - val_output_2_acc: 0.5354\n",
      "Epoch 8/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.4067 - output_1_loss: -0.0026 - output_2_loss: 1.4093 - output_1_acc: 0.0429 - output_2_acc: 0.6384\n",
      "Epoch 00008: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4063 - output_1_loss: -0.0029 - output_2_loss: 1.4091 - output_1_acc: 0.0429 - output_2_acc: 0.6384 - val_loss: 1.3543 - val_output_1_loss: -0.0149 - val_output_2_loss: 1.3692 - val_output_1_acc: 0.0248 - val_output_2_acc: 0.5335\n",
      "Epoch 9/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.4002 - output_1_loss: -0.0099 - output_2_loss: 1.4101 - output_1_acc: 0.0410 - output_2_acc: 0.6366\n",
      "Epoch 00009: val_output_2_acc improved from 0.53942 to 0.54083, saving model to modelMIX9.h5\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4005 - output_1_loss: -0.0098 - output_2_loss: 1.4103 - output_1_acc: 0.0410 - output_2_acc: 0.6365 - val_loss: 1.3526 - val_output_1_loss: -7.3096e-04 - val_output_2_loss: 1.3534 - val_output_1_acc: 0.0227 - val_output_2_acc: 0.5408\n",
      "Epoch 10/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.4007 - output_1_loss: -0.0091 - output_2_loss: 1.4097 - output_1_acc: 0.0401 - output_2_acc: 0.6348\n",
      "Epoch 00010: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4011 - output_1_loss: -0.0088 - output_2_loss: 1.4098 - output_1_acc: 0.0401 - output_2_acc: 0.6348 - val_loss: 1.3989 - val_output_1_loss: 0.0061 - val_output_2_loss: 1.3928 - val_output_1_acc: 0.0259 - val_output_2_acc: 0.5375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.3990 - output_1_loss: -0.0036 - output_2_loss: 1.4026 - output_1_acc: 0.0413 - output_2_acc: 0.6421\n",
      "Epoch 00011: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.3995 - output_1_loss: -0.0033 - output_2_loss: 1.4029 - output_1_acc: 0.0413 - output_2_acc: 0.6419 - val_loss: 1.4287 - val_output_1_loss: -3.5642e-04 - val_output_2_loss: 1.4291 - val_output_1_acc: 0.0288 - val_output_2_acc: 0.5312\n",
      "Epoch 12/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.4172 - output_1_loss: 0.0111 - output_2_loss: 1.4062 - output_1_acc: 0.0411 - output_2_acc: 0.6422\n",
      "Epoch 00012: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4172 - output_1_loss: 0.0111 - output_2_loss: 1.4061 - output_1_acc: 0.0411 - output_2_acc: 0.6422 - val_loss: 1.4173 - val_output_1_loss: 0.0076 - val_output_2_loss: 1.4098 - val_output_1_acc: 0.0313 - val_output_2_acc: 0.5326\n",
      "Epoch 13/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.3966 - output_1_loss: -0.0059 - output_2_loss: 1.4026 - output_1_acc: 0.0415 - output_2_acc: 0.6373\n",
      "Epoch 00013: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.3964 - output_1_loss: -0.0062 - output_2_loss: 1.4026 - output_1_acc: 0.0415 - output_2_acc: 0.6372 - val_loss: 1.4008 - val_output_1_loss: 0.0040 - val_output_2_loss: 1.3968 - val_output_1_acc: 0.0374 - val_output_2_acc: 0.5389\n",
      "Epoch 14/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.4405 - output_1_loss: 0.0316 - output_2_loss: 1.4090 - output_1_acc: 0.0409 - output_2_acc: 0.6427\n",
      "Epoch 00014: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4418 - output_1_loss: 0.0325 - output_2_loss: 1.4093 - output_1_acc: 0.0410 - output_2_acc: 0.6426 - val_loss: 1.4214 - val_output_1_loss: 0.0081 - val_output_2_loss: 1.4134 - val_output_1_acc: 0.0259 - val_output_2_acc: 0.5392\n",
      "Epoch 15/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.3937 - output_1_loss: -0.0058 - output_2_loss: 1.3995 - output_1_acc: 0.0416 - output_2_acc: 0.6418\n",
      "Epoch 00015: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.3933 - output_1_loss: -0.0061 - output_2_loss: 1.3994 - output_1_acc: 0.0415 - output_2_acc: 0.6419 - val_loss: 1.4188 - val_output_1_loss: 0.0010 - val_output_2_loss: 1.4178 - val_output_1_acc: 0.0245 - val_output_2_acc: 0.5357\n",
      "Epoch 16/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.3833 - output_1_loss: -0.0157 - output_2_loss: 1.3990 - output_1_acc: 0.0408 - output_2_acc: 0.6425\n",
      "Epoch 00016: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.3829 - output_1_loss: -0.0160 - output_2_loss: 1.3989 - output_1_acc: 0.0408 - output_2_acc: 0.6425 - val_loss: 1.4234 - val_output_1_loss: -4.2715e-04 - val_output_2_loss: 1.4238 - val_output_1_acc: 0.0252 - val_output_2_acc: 0.5312\n",
      "Epoch 17/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.4013 - output_1_loss: -0.0015 - output_2_loss: 1.4028 - output_1_acc: 0.0388 - output_2_acc: 0.6431\n",
      "Epoch 00017: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4010 - output_1_loss: -0.0017 - output_2_loss: 1.4027 - output_1_acc: 0.0388 - output_2_acc: 0.6431 - val_loss: 1.4072 - val_output_1_loss: -0.0016 - val_output_2_loss: 1.4088 - val_output_1_acc: 0.0217 - val_output_2_acc: 0.5374\n",
      "Epoch 18/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.3943 - output_1_loss: -0.0035 - output_2_loss: 1.3978 - output_1_acc: 0.0408 - output_2_acc: 0.6459\n",
      "Epoch 00018: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.3942 - output_1_loss: -0.0035 - output_2_loss: 1.3977 - output_1_acc: 0.0407 - output_2_acc: 0.6459 - val_loss: 1.4223 - val_output_1_loss: 0.0016 - val_output_2_loss: 1.4207 - val_output_1_acc: 0.0320 - val_output_2_acc: 0.5352\n",
      "Epoch 19/20\n",
      "1595/1596 [============================>.] - ETA: 0s - loss: 1.3994 - output_1_loss: 6.7780e-04 - output_2_loss: 1.3987 - output_1_acc: 0.0414 - output_2_acc: 0.6411\n",
      "Epoch 00019: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 71s 45ms/step - loss: 1.4000 - output_1_loss: 0.0011 - output_2_loss: 1.3989 - output_1_acc: 0.0414 - output_2_acc: 0.6412 - val_loss: 1.4401 - val_output_1_loss: -0.0072 - val_output_2_loss: 1.4474 - val_output_1_acc: 0.0327 - val_output_2_acc: 0.5291\n",
      "Epoch 20/20\n",
      "1594/1596 [============================>.] - ETA: 0s - loss: 1.4048 - output_1_loss: 0.0043 - output_2_loss: 1.4005 - output_1_acc: 0.0400 - output_2_acc: 0.6436\n",
      "Epoch 00020: val_output_2_acc did not improve\n",
      "1596/1596 [==============================] - 72s 45ms/step - loss: 1.4059 - output_1_loss: 0.0050 - output_2_loss: 1.4009 - output_1_acc: 0.0401 - output_2_acc: 0.6436 - val_loss: 1.4941 - val_output_1_loss: 0.0074 - val_output_2_loss: 1.4867 - val_output_1_acc: 0.0348 - val_output_2_acc: 0.5257\n",
      "Evaluating scd_dataset\n",
      "6798/6798 [==============================] - 10s 1ms/step\n",
      " = 0.9349808767284495\n",
      "Evaluating usd_dataset\n",
      "990/990 [==============================] - 1s 1ms/step\n",
      " = 0.5292929292929293\n",
      "Accuracy with scd_dataset = 0.934981\n",
      "Accuracy with usd_dataset = 0.529293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9349808767284495, 0.5292929292929293]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine tune for scd\n",
    "multi = MultiDataset([scd, usd], [1.0, 0.0])\n",
    "\n",
    "model = model_mlt_cnn_alexnet(multi.input_shape(), multi.ys_classes(), freeze_mode=1)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "model.load_weights('model%s.h5' % BASE) ### Starting point\n",
    "\n",
    "callbacks = [\n",
    "    CyclicLR(base_lr=0.00007, max_lr=0.0007, step_size=multi.train_steps_per_epoch, mode='triangular'),\n",
    "    ModelCheckpoint('model%s.h5' % TRY,\n",
    "                monitor='val_output_1_acc',\n",
    "                verbose=1,\n",
    "                save_best_only=True,\n",
    "                save_weights_only=True),\n",
    "     keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=0, write_graph=True, write_images=True)\n",
    "]\n",
    "model.fit_generator(multi.train_generator,\n",
    "                    steps_per_epoch=multi.train_steps_per_epoch,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=multi.valid_generator, \n",
    "                    validation_steps=multi.valid_steps_per_epoch,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "multi.evaluate_by_datasets(model)\n",
    "\n",
    "# Fine tune for usd\n",
    "multi = MultiDataset([scd, usd], [0.0, 1.0])\n",
    "\n",
    "model = model_mlt_cnn_alexnet(multi.input_shape(), multi.ys_classes(), freeze_mode=2)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "model.load_weights('model%s.h5' % TRY)\n",
    "\n",
    "callbacks = [\n",
    "    CyclicLR(base_lr=0.00007, max_lr=0.0007, step_size=multi.train_steps_per_epoch, mode='triangular'),\n",
    "    ModelCheckpoint('model%s.h5' % TRY,\n",
    "                monitor='val_output_2_acc',\n",
    "                verbose=1,\n",
    "                save_best_only=True,\n",
    "                save_weights_only=True),\n",
    "     keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=0, write_graph=True, write_images=True)\n",
    "]\n",
    "model.fit_generator(multi.train_generator,\n",
    "                    steps_per_epoch=multi.train_steps_per_epoch,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=multi.valid_generator, \n",
    "                    validation_steps=multi.valid_steps_per_epoch,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "multi.evaluate_by_datasets(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating scd_dataset\n",
      "6798/6798 [==============================] - 10s 1ms/step\n",
      " = 0.9349808767284495\n",
      "Evaluating usd_dataset\n",
      "990/990 [==============================] - 1s 2ms/step\n",
      " = 0.5434343434343434\n",
      "Accuracy with scd_dataset = 0.934981\n",
      "Accuracy with usd_dataset = 0.543434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9349808767284495, 0.5434343434343434]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('model%s.h5' % TRY)\n",
    "multi.evaluate_by_datasets(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate by mixed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'output_1_loss', 'output_2_loss', 'output_1_acc', 'output_2_acc'] [0.8975593357958745, 0.26930842500272806, 0.6282509113889155, 0.8967642526964561, 0.4619928094504366]\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('model%s.h5' % TRY)\n",
    "multi = MultiDataset([scd, usd], [0.6, 0.4], mix_randomness=0.0)\n",
    "results = model.evaluate_generator(multi.valid_generator, steps=multi.valid_steps_per_epoch)\n",
    "print(model.metrics_names, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
