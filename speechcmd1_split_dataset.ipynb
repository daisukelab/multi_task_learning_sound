{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset\n",
    "\n",
    "- [Link to Speech Commands Dataset description](https://research.googleblog.com/2017/08/launching-speech-commands-dataset.html)\n",
    "\n",
    "The dataset has lists of validation and test data.\n",
    "\n",
    "Then here we define complete sets of training, validation and test for further evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "DATADIR = '../../dataset/speech_commands_v0.01'\n",
    "DATASET_PREFIX = 'scd_'\n",
    "\n",
    "# Get whole list of files\n",
    "fullwavs = [f.replace(DATADIR+'/', '') for f in glob.glob(os.path.join(DATADIR, '*/*.wav'))]\n",
    "# Remove if it begin with _ (removing _background_noise_)\n",
    "wavs = [f for f in fullwavs if f[0] != '_']\n",
    "\n",
    "# Load valid/test list, then set train list as (wavs - valid - test)\n",
    "with open(os.path.join(DATADIR, 'validation_list.txt')) as f:\n",
    "    validlist = f.read().splitlines()\n",
    "with open(os.path.join(DATADIR, 'testing_list.txt')) as f:\n",
    "    testlist = f.read().splitlines()\n",
    "trainlist = [f for f in wavs if (not (f in validlist) and  not (f in testlist))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files ist= 64727\n",
      "Available speech files = 64721\n",
      "Training files = 51088\n",
      "Validation files = 6798\n",
      "Test files = 6835\n"
     ]
    }
   ],
   "source": [
    "print('Total number of files ist=', len(fullwavs))\n",
    "print('Available speech files =', len(wavs))\n",
    "print('Training files =', len(trainlist))\n",
    "print('Validation files =', len(validlist))\n",
    "print('Test files =', len(testlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 classes are ['eight', 'one', 'tree', 'bird', 'two', 'seven', 'down', 'yes', 'off', 'nine', 'no', 'up', 'cat', 'left', 'bed', 'dog', 'marvin', 'happy', 'right', 'on', 'wow', 'three', 'sheila', 'stop', 'house', 'zero', 'five', 'four', 'go', 'six']\n"
     ]
    }
   ],
   "source": [
    "clslist = list(set([f.split('/')[0] for f in testlist]))\n",
    "print('%d classes are' % len(clslist), clslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_distribution [1852, 1892, 1374, 1411, 1873, 1875, 1842, 1860, 1839, 1875, 1853, 1843, 1399, 1839, 1340, 1396, 1424, 1373, 1852, 1864, 1414, 1841, 1372, 1885, 1427, 1866, 1844, 1839, 1861, 1863]\n",
      "valid_distribution [243, 230, 166, 162, 236, 263, 264, 261, 256, 230, 270, 260, 168, 247, 197, 170, 160, 189, 256, 257, 166, 248, 176, 246, 173, 260, 242, 280, 260, 262]\n",
      "test_distribution [257, 248, 193, 158, 264, 239, 253, 256, 262, 259, 252, 272, 166, 267, 176, 180, 162, 180, 259, 246, 165, 267, 186, 249, 150, 250, 271, 253, 251, 244]\n"
     ]
    }
   ],
   "source": [
    "print('train_distribution', [len([f for f in trainlist if f.split('/')[0] == cls]) for cls in clslist])\n",
    "print('valid_distribution', [len([f for f in validlist if f.split('/')[0] == cls]) for cls in clslist])\n",
    "print('test_distribution', [len([f for f in testlist if f.split('/')[0] == cls]) for cls in clslist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It's imbalanced among classes... but it's ok for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('.', DATASET_PREFIX+'trainset.txt'), 'w') as f:\n",
    "    f.write('\\n'.join(trainlist)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('.', DATASET_PREFIX+'validationset.txt'), 'w') as f:\n",
    "    f.write('\\n'.join(validlist)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('.', DATASET_PREFIX+'testset.txt'), 'w') as f:\n",
    "    f.write('\\n'.join(testlist)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('.', DATASET_PREFIX+'classes.txt'), 'w') as f:\n",
    "    f.write('\\n'.join(clslist)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Duplication(Leakage) test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ids = list(set([fn.split('/')[1].split('_')[0] for fn in trainlist]))\n",
    "valid_ids = list(set([fn.split('/')[1].split('_')[0] for fn in validlist]))\n",
    "test_ids = list(set([fn.split('/')[1].split('_')[0] for fn in testlist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "fsIDs = [train_ids, valid_ids, test_ids]\n",
    "for i, j in itertools.combinations(range(len(fsIDs)), 2):\n",
    "    _or = np.append(fsIDs[i], fsIDs[j])\n",
    "    _and = np.unique(_or)\n",
    "    if len(_or) != len(_and):\n",
    "        print('Duplicated in set %d and %d, for %d sources' % (i, j, len(_or) - len(_and)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No output, then no leakage..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
